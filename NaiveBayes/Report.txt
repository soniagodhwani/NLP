Assignment 1 Report

Name: Sonia Godhwani

1. Performance on the development data with 100% of the training data
1a. spam precision: 0.993088194636439
1b. spam recall: 0.9774149659863945
1c. spam F1 score: 0.9851892484914975
1d. ham precision: 0.9467265725288831
1e. ham recall: 0.9833333333333333
1f. ham F1 score: 0.9646827992151734

2. Performance on the development data with 10% of the training data
2a. spam precision: 0.987699189264747
2b. spam recall: 0.9613605442176871
2c. spam F1 score: 0.9743519029233316
2d. ham precision: 0.9111389236545682
2e. ham recall: 0.9706666666666667
2f. ham F1 score: 0.9399612653324725

3. Description of enhancement(s) you tried (e.g., different approach(es) to smoothing, treating common words differently, dealing with unknown words differently):
1)Smoothing - Dirichlet smoothing with Mu = 0.39. The F1 score was improved for both the categories. The recall and preciion improved for spam but got worse for ham.
Then I tried it for different values of Mu and the results were the same.
2)The second approach I tried was using the words after stemming using nltk and creating the nbmodel.txt of only stemmed words. None of the parameters improved.
3)Lastly, I tried filtering out Stopwords of nltk and non-alpha-numeric words and only considering these filtered words. All the values were improved and it gave the best result out of the approches I tried.

4. Best performance results based on enhancements. Note that these could be the same or worse than the standard implementation.
4a. spam precision: 0.9964177459355195
4b. spam recall: 0.9839455782312925
4c. spam F1 score: 0.9901423877327492
4d. ham precision: 0.961836998706339
4e. ham recall: 0.9913333333333333
4f. ham F1 score: 0.9567496723460027
